{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.0005\n",
    "num_epoch = 20\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data_CVAE/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_CVAE/MNIST/raw/train-images-idx3-ubyte.gz to ./data_CVAE/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data_CVAE/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_CVAE/MNIST/raw/train-labels-idx1-ubyte.gz to ./data_CVAE/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data_CVAE/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_CVAE/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data_CVAE/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data_CVAE/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data_CVAE/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data_CVAE/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dataset.MNIST(\"./data_CVAE\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dataset.MNIST(\"./data_CVAE\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils. data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = torch.utils. data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "                        nn.Conv2d(1, 8, 3, padding=1),# batch x 8 * 28 * 28\n",
    "                        nn.BatchNorm2d(8),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        nn.Conv2d(8, 16, 3, padding=1),#batch x 16 * 14 * 14\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        nn.Conv2d(16, 32, 3, padding=1),#batch x 32 * 7 * 7\n",
    "                        nn.ReLU(),\n",
    "        )\n",
    "        self.fc2_1 = nn.Sequential(\n",
    "                            nn.Linear(32*7*7, 800),\n",
    "                            nn.Linear(800, hidden_size),\n",
    "        )\n",
    "        self.fc2_2 = nn.Sequential(\n",
    "                            nn.Linear(32*7*7, 800),\n",
    "                            nn.Linear(800, hidden_size),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.relu(out)\n",
    "        mu = self.fc2_1(out)\n",
    "        log_var = self.fc2_2(out)\n",
    "        \n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        reparam = self.reparameterize(mu, logvar)\n",
    "        return mu, logvar, reparam\n",
    "    \n",
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "                        nn.Linear(hidden_size, 800),\n",
    "                        nn.BatchNorm1d(800),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(800, 1568),\n",
    "                        nn.ReLU(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                        nn.ConvTranspose2d(32, 16, 3, 2, 1, 1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(16),\n",
    "                        nn.ConvTranspose2d(16, 8, 3, 2, 1, 1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(8),\n",
    "                        nn.ConvTranspose2d(8, 1, 3, 1, 1),\n",
    "                        nn.BatchNorm2d(1),\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = out.view(batch_size, 32, 7, 7)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = out.view(batch_size, 28, 28, 1)\n",
    "        \n",
    "        return out \n",
    "    \n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "reconstruction_function = nn.BCELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "    \n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    \n",
    "    return BCE + KLD\n",
    "\n",
    "parameters = list(encoder.parameters()) + list(decoder.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------model not restored----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([128, 1, 28, 28])) that is different to the input size (torch.Size([128, 28, 28, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/amore/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sigmoid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(80250.8359, grad_fn=<AddBackward0>)\n",
      "tensor(66831.0312, grad_fn=<AddBackward0>)\n",
      "tensor(63816.9102, grad_fn=<AddBackward0>)\n",
      "tensor(62233.7266, grad_fn=<AddBackward0>)\n",
      "tensor(61621.0352, grad_fn=<AddBackward0>)\n",
      "tensor(60327.5391, grad_fn=<AddBackward0>)\n",
      "tensor(59597.8203, grad_fn=<AddBackward0>)\n",
      "tensor(58976.2656, grad_fn=<AddBackward0>)\n",
      "tensor(58019.7656, grad_fn=<AddBackward0>)\n",
      "tensor(57510.2344, grad_fn=<AddBackward0>)\n",
      "tensor(57318.5469, grad_fn=<AddBackward0>)\n",
      "tensor(56948.6055, grad_fn=<AddBackward0>)\n",
      "tensor(55920.7812, grad_fn=<AddBackward0>)\n",
      "tensor(56729.0078, grad_fn=<AddBackward0>)\n",
      "tensor(54851.8984, grad_fn=<AddBackward0>)\n",
      "tensor(55863.8047, grad_fn=<AddBackward0>)\n",
      "tensor(55040.3242, grad_fn=<AddBackward0>)\n",
      "tensor(54555.1016, grad_fn=<AddBackward0>)\n",
      "tensor(54736.7656, grad_fn=<AddBackward0>)\n",
      "tensor(53938.2031, grad_fn=<AddBackward0>)\n",
      "tensor(53846.7852, grad_fn=<AddBackward0>)\n",
      "tensor(53883.1328, grad_fn=<AddBackward0>)\n",
      "tensor(53090.6172, grad_fn=<AddBackward0>)\n",
      "tensor(53331.6328, grad_fn=<AddBackward0>)\n",
      "tensor(53531.7734, grad_fn=<AddBackward0>)\n",
      "tensor(53132.3086, grad_fn=<AddBackward0>)\n",
      "tensor(52408.9297, grad_fn=<AddBackward0>)\n",
      "tensor(51717.3086, grad_fn=<AddBackward0>)\n",
      "tensor(52157.5664, grad_fn=<AddBackward0>)\n",
      "tensor(50866.1328, grad_fn=<AddBackward0>)\n",
      "tensor(51765.3125, grad_fn=<AddBackward0>)\n",
      "tensor(51285.4492, grad_fn=<AddBackward0>)\n",
      "tensor(50140.1484, grad_fn=<AddBackward0>)\n",
      "tensor(50428.4219, grad_fn=<AddBackward0>)\n",
      "tensor(50068.0039, grad_fn=<AddBackward0>)\n",
      "tensor(49726.1484, grad_fn=<AddBackward0>)\n",
      "tensor(49571.0703, grad_fn=<AddBackward0>)\n",
      "tensor(50121.2539, grad_fn=<AddBackward0>)\n",
      "tensor(49348.8906, grad_fn=<AddBackward0>)\n",
      "tensor(49150.2227, grad_fn=<AddBackward0>)\n",
      "tensor(49338.4414, grad_fn=<AddBackward0>)\n",
      "tensor(48641.4141, grad_fn=<AddBackward0>)\n",
      "tensor(48813.5195, grad_fn=<AddBackward0>)\n",
      "tensor(48871.8711, grad_fn=<AddBackward0>)\n",
      "tensor(48617.8125, grad_fn=<AddBackward0>)\n",
      "tensor(48604.0703, grad_fn=<AddBackward0>)\n",
      "tensor(47306.0352, grad_fn=<AddBackward0>)\n",
      "tensor(47363.7930, grad_fn=<AddBackward0>)\n",
      "tensor(46704.1562, grad_fn=<AddBackward0>)\n",
      "tensor(46878.7266, grad_fn=<AddBackward0>)\n",
      "tensor(46827.5273, grad_fn=<AddBackward0>)\n",
      "tensor(46485.3906, grad_fn=<AddBackward0>)\n",
      "tensor(47349.2148, grad_fn=<AddBackward0>)\n",
      "tensor(46308.8789, grad_fn=<AddBackward0>)\n",
      "tensor(45920.5195, grad_fn=<AddBackward0>)\n",
      "tensor(45988.1055, grad_fn=<AddBackward0>)\n",
      "tensor(45857.0156, grad_fn=<AddBackward0>)\n",
      "tensor(45807.2891, grad_fn=<AddBackward0>)\n",
      "tensor(44681.6211, grad_fn=<AddBackward0>)\n",
      "tensor(44320.3008, grad_fn=<AddBackward0>)\n",
      "tensor(44798.3828, grad_fn=<AddBackward0>)\n",
      "tensor(44383.6484, grad_fn=<AddBackward0>)\n",
      "tensor(44560.4570, grad_fn=<AddBackward0>)\n",
      "tensor(44132.6719, grad_fn=<AddBackward0>)\n",
      "tensor(43920.2930, grad_fn=<AddBackward0>)\n",
      "tensor(43573.6172, grad_fn=<AddBackward0>)\n",
      "tensor(44244.5078, grad_fn=<AddBackward0>)\n",
      "tensor(43892.0469, grad_fn=<AddBackward0>)\n",
      "tensor(44098.2344, grad_fn=<AddBackward0>)\n",
      "tensor(43424.3164, grad_fn=<AddBackward0>)\n",
      "tensor(43534.9961, grad_fn=<AddBackward0>)\n",
      "tensor(42955.7227, grad_fn=<AddBackward0>)\n",
      "tensor(42378.0820, grad_fn=<AddBackward0>)\n",
      "tensor(42278.8398, grad_fn=<AddBackward0>)\n",
      "tensor(42958.8398, grad_fn=<AddBackward0>)\n",
      "tensor(42357.4141, grad_fn=<AddBackward0>)\n",
      "tensor(42359.7539, grad_fn=<AddBackward0>)\n",
      "tensor(42238.4141, grad_fn=<AddBackward0>)\n",
      "tensor(41719.8398, grad_fn=<AddBackward0>)\n",
      "tensor(41852.5625, grad_fn=<AddBackward0>)\n",
      "tensor(41808.3398, grad_fn=<AddBackward0>)\n",
      "tensor(40708.0820, grad_fn=<AddBackward0>)\n",
      "tensor(40874.4062, grad_fn=<AddBackward0>)\n",
      "tensor(40748.3984, grad_fn=<AddBackward0>)\n",
      "tensor(41321.8359, grad_fn=<AddBackward0>)\n",
      "tensor(41234.3281, grad_fn=<AddBackward0>)\n",
      "tensor(40056.6953, grad_fn=<AddBackward0>)\n",
      "tensor(40544.4766, grad_fn=<AddBackward0>)\n",
      "tensor(40806.8281, grad_fn=<AddBackward0>)\n",
      "tensor(40068.1406, grad_fn=<AddBackward0>)\n",
      "tensor(39417.4336, grad_fn=<AddBackward0>)\n",
      "tensor(39252.4414, grad_fn=<AddBackward0>)\n",
      "tensor(39319.3203, grad_fn=<AddBackward0>)\n",
      "tensor(39607.5703, grad_fn=<AddBackward0>)\n",
      "tensor(39811.7539, grad_fn=<AddBackward0>)\n",
      "tensor(39441.8281, grad_fn=<AddBackward0>)\n",
      "tensor(39199.4453, grad_fn=<AddBackward0>)\n",
      "tensor(39481.2422, grad_fn=<AddBackward0>)\n",
      "tensor(39498.2031, grad_fn=<AddBackward0>)\n",
      "tensor(38967.8555, grad_fn=<AddBackward0>)\n",
      "tensor(38823.2266, grad_fn=<AddBackward0>)\n",
      "tensor(38818.9492, grad_fn=<AddBackward0>)\n",
      "tensor(38708.8789, grad_fn=<AddBackward0>)\n",
      "tensor(37925.9766, grad_fn=<AddBackward0>)\n",
      "tensor(38019.6836, grad_fn=<AddBackward0>)\n",
      "tensor(38134.9531, grad_fn=<AddBackward0>)\n",
      "tensor(38443.2266, grad_fn=<AddBackward0>)\n",
      "tensor(37441.5117, grad_fn=<AddBackward0>)\n",
      "tensor(37238.8945, grad_fn=<AddBackward0>)\n",
      "tensor(37158.3086, grad_fn=<AddBackward0>)\n",
      "tensor(37466.4766, grad_fn=<AddBackward0>)\n",
      "tensor(36930.8438, grad_fn=<AddBackward0>)\n",
      "tensor(36794.3203, grad_fn=<AddBackward0>)\n",
      "tensor(36569.4297, grad_fn=<AddBackward0>)\n",
      "tensor(36722.4609, grad_fn=<AddBackward0>)\n",
      "tensor(37194.6289, grad_fn=<AddBackward0>)\n",
      "tensor(36147.3242, grad_fn=<AddBackward0>)\n",
      "tensor(36529.5703, grad_fn=<AddBackward0>)\n",
      "tensor(36229.9414, grad_fn=<AddBackward0>)\n",
      "tensor(36500.1133, grad_fn=<AddBackward0>)\n",
      "tensor(36430.5039, grad_fn=<AddBackward0>)\n",
      "tensor(35734.8047, grad_fn=<AddBackward0>)\n",
      "tensor(35351.0625, grad_fn=<AddBackward0>)\n",
      "tensor(35808.3516, grad_fn=<AddBackward0>)\n",
      "tensor(36209.6211, grad_fn=<AddBackward0>)\n",
      "tensor(35493.7891, grad_fn=<AddBackward0>)\n",
      "tensor(35490.9102, grad_fn=<AddBackward0>)\n",
      "tensor(35175.9141, grad_fn=<AddBackward0>)\n",
      "tensor(34467.1367, grad_fn=<AddBackward0>)\n",
      "tensor(35262.7461, grad_fn=<AddBackward0>)\n",
      "tensor(34966.5703, grad_fn=<AddBackward0>)\n",
      "tensor(34567.7969, grad_fn=<AddBackward0>)\n",
      "tensor(34764.5000, grad_fn=<AddBackward0>)\n",
      "tensor(35283.9453, grad_fn=<AddBackward0>)\n",
      "tensor(35218.8125, grad_fn=<AddBackward0>)\n",
      "tensor(34597.6445, grad_fn=<AddBackward0>)\n",
      "tensor(34620.0117, grad_fn=<AddBackward0>)\n",
      "tensor(34151.0742, grad_fn=<AddBackward0>)\n",
      "tensor(34711.7383, grad_fn=<AddBackward0>)\n",
      "tensor(33913.2344, grad_fn=<AddBackward0>)\n",
      "tensor(33846.7188, grad_fn=<AddBackward0>)\n",
      "tensor(33904.0469, grad_fn=<AddBackward0>)\n",
      "tensor(33625.1367, grad_fn=<AddBackward0>)\n",
      "tensor(33559.5898, grad_fn=<AddBackward0>)\n",
      "tensor(34472.4258, grad_fn=<AddBackward0>)\n",
      "tensor(34031.5000, grad_fn=<AddBackward0>)\n",
      "tensor(33299.5859, grad_fn=<AddBackward0>)\n",
      "tensor(32859.3320, grad_fn=<AddBackward0>)\n",
      "tensor(32843.0781, grad_fn=<AddBackward0>)\n",
      "tensor(33157.0859, grad_fn=<AddBackward0>)\n",
      "tensor(32841.3750, grad_fn=<AddBackward0>)\n",
      "tensor(32892.7070, grad_fn=<AddBackward0>)\n",
      "tensor(33242.8164, grad_fn=<AddBackward0>)\n",
      "tensor(32773.0156, grad_fn=<AddBackward0>)\n",
      "tensor(32432.0977, grad_fn=<AddBackward0>)\n",
      "tensor(32791.4414, grad_fn=<AddBackward0>)\n",
      "tensor(32616.6055, grad_fn=<AddBackward0>)\n",
      "tensor(32097.7383, grad_fn=<AddBackward0>)\n",
      "tensor(32256.9277, grad_fn=<AddBackward0>)\n",
      "tensor(32535.9844, grad_fn=<AddBackward0>)\n",
      "tensor(31913.2090, grad_fn=<AddBackward0>)\n",
      "tensor(32000.9824, grad_fn=<AddBackward0>)\n",
      "tensor(32209.1035, grad_fn=<AddBackward0>)\n",
      "tensor(31830.6602, grad_fn=<AddBackward0>)\n",
      "tensor(32075.8906, grad_fn=<AddBackward0>)\n",
      "tensor(31469.6641, grad_fn=<AddBackward0>)\n",
      "tensor(31176.9844, grad_fn=<AddBackward0>)\n",
      "tensor(31695.9922, grad_fn=<AddBackward0>)\n",
      "tensor(31498.2285, grad_fn=<AddBackward0>)\n",
      "tensor(31523.3125, grad_fn=<AddBackward0>)\n",
      "tensor(31267.0820, grad_fn=<AddBackward0>)\n",
      "tensor(31419.4570, grad_fn=<AddBackward0>)\n",
      "tensor(30897.0117, grad_fn=<AddBackward0>)\n",
      "tensor(31062.4336, grad_fn=<AddBackward0>)\n",
      "tensor(31804.1445, grad_fn=<AddBackward0>)\n",
      "tensor(31972.0938, grad_fn=<AddBackward0>)\n",
      "tensor(30635.2617, grad_fn=<AddBackward0>)\n",
      "tensor(30753.1133, grad_fn=<AddBackward0>)\n",
      "tensor(30184.5527, grad_fn=<AddBackward0>)\n",
      "tensor(30570.5234, grad_fn=<AddBackward0>)\n",
      "tensor(29529.3633, grad_fn=<AddBackward0>)\n",
      "tensor(30154.5508, grad_fn=<AddBackward0>)\n",
      "tensor(30029.1348, grad_fn=<AddBackward0>)\n",
      "tensor(29722.5469, grad_fn=<AddBackward0>)\n",
      "tensor(29701.4375, grad_fn=<AddBackward0>)\n",
      "tensor(29836.8008, grad_fn=<AddBackward0>)\n",
      "tensor(30304.7559, grad_fn=<AddBackward0>)\n",
      "tensor(29995.9414, grad_fn=<AddBackward0>)\n",
      "tensor(28818.8770, grad_fn=<AddBackward0>)\n",
      "tensor(29204.9688, grad_fn=<AddBackward0>)\n",
      "tensor(29641.8848, grad_fn=<AddBackward0>)\n",
      "tensor(29717.9297, grad_fn=<AddBackward0>)\n",
      "tensor(29341.3867, grad_fn=<AddBackward0>)\n",
      "tensor(29104.6035, grad_fn=<AddBackward0>)\n",
      "tensor(29483.2969, grad_fn=<AddBackward0>)\n",
      "tensor(29098.9785, grad_fn=<AddBackward0>)\n",
      "tensor(28778.2812, grad_fn=<AddBackward0>)\n",
      "tensor(28982.0781, grad_fn=<AddBackward0>)\n",
      "tensor(28850.3145, grad_fn=<AddBackward0>)\n",
      "tensor(28591.9453, grad_fn=<AddBackward0>)\n",
      "tensor(29201.1133, grad_fn=<AddBackward0>)\n",
      "tensor(28875.1602, grad_fn=<AddBackward0>)\n",
      "tensor(28753.4375, grad_fn=<AddBackward0>)\n",
      "tensor(28966.7598, grad_fn=<AddBackward0>)\n",
      "tensor(28348.2246, grad_fn=<AddBackward0>)\n",
      "tensor(28746.7676, grad_fn=<AddBackward0>)\n",
      "tensor(28477.2871, grad_fn=<AddBackward0>)\n",
      "tensor(28270.6289, grad_fn=<AddBackward0>)\n",
      "tensor(28679.4805, grad_fn=<AddBackward0>)\n",
      "tensor(28071.6875, grad_fn=<AddBackward0>)\n",
      "tensor(28279.7949, grad_fn=<AddBackward0>)\n",
      "tensor(27830.5078, grad_fn=<AddBackward0>)\n",
      "tensor(27915.4766, grad_fn=<AddBackward0>)\n",
      "tensor(27793.3828, grad_fn=<AddBackward0>)\n",
      "tensor(27863.3984, grad_fn=<AddBackward0>)\n",
      "tensor(27698.9473, grad_fn=<AddBackward0>)\n",
      "tensor(27699.6035, grad_fn=<AddBackward0>)\n",
      "tensor(27287.6543, grad_fn=<AddBackward0>)\n",
      "tensor(27917.2617, grad_fn=<AddBackward0>)\n",
      "tensor(27213.2617, grad_fn=<AddBackward0>)\n",
      "tensor(27058.0078, grad_fn=<AddBackward0>)\n",
      "tensor(27336.0918, grad_fn=<AddBackward0>)\n",
      "tensor(27784.4355, grad_fn=<AddBackward0>)\n",
      "tensor(27042.3789, grad_fn=<AddBackward0>)\n",
      "tensor(27423.9473, grad_fn=<AddBackward0>)\n",
      "tensor(27174.0586, grad_fn=<AddBackward0>)\n",
      "tensor(28003.0156, grad_fn=<AddBackward0>)\n",
      "tensor(27241.8281, grad_fn=<AddBackward0>)\n",
      "tensor(26564.7207, grad_fn=<AddBackward0>)\n",
      "tensor(26317.4922, grad_fn=<AddBackward0>)\n",
      "tensor(27358.9297, grad_fn=<AddBackward0>)\n",
      "tensor(27098.6035, grad_fn=<AddBackward0>)\n",
      "tensor(27044.3633, grad_fn=<AddBackward0>)\n",
      "tensor(26877.9512, grad_fn=<AddBackward0>)\n",
      "tensor(26904.6582, grad_fn=<AddBackward0>)\n",
      "tensor(27011.9277, grad_fn=<AddBackward0>)\n",
      "tensor(26002.1562, grad_fn=<AddBackward0>)\n",
      "tensor(26752.3984, grad_fn=<AddBackward0>)\n",
      "tensor(26496.6719, grad_fn=<AddBackward0>)\n",
      "tensor(26543.3633, grad_fn=<AddBackward0>)\n",
      "tensor(26367.8242, grad_fn=<AddBackward0>)\n",
      "tensor(26658.5352, grad_fn=<AddBackward0>)\n",
      "tensor(26373.2422, grad_fn=<AddBackward0>)\n",
      "tensor(25680.0176, grad_fn=<AddBackward0>)\n",
      "tensor(26210.3906, grad_fn=<AddBackward0>)\n",
      "tensor(26678.1738, grad_fn=<AddBackward0>)\n",
      "tensor(25864.2773, grad_fn=<AddBackward0>)\n",
      "tensor(26025.4004, grad_fn=<AddBackward0>)\n",
      "tensor(25549.8320, grad_fn=<AddBackward0>)\n",
      "tensor(25555.5586, grad_fn=<AddBackward0>)\n",
      "tensor(26174.9492, grad_fn=<AddBackward0>)\n",
      "tensor(25934.6582, grad_fn=<AddBackward0>)\n",
      "tensor(25948.4941, grad_fn=<AddBackward0>)\n",
      "tensor(25736.4570, grad_fn=<AddBackward0>)\n",
      "tensor(25362.9473, grad_fn=<AddBackward0>)\n",
      "tensor(26023.3555, grad_fn=<AddBackward0>)\n",
      "tensor(25089.4609, grad_fn=<AddBackward0>)\n",
      "tensor(26120.3633, grad_fn=<AddBackward0>)\n",
      "tensor(25511.6543, grad_fn=<AddBackward0>)\n",
      "tensor(25185.0137, grad_fn=<AddBackward0>)\n",
      "tensor(25170.2852, grad_fn=<AddBackward0>)\n",
      "tensor(25132.0156, grad_fn=<AddBackward0>)\n",
      "tensor(24827.4121, grad_fn=<AddBackward0>)\n",
      "tensor(25136.7031, grad_fn=<AddBackward0>)\n",
      "tensor(25014.5977, grad_fn=<AddBackward0>)\n",
      "tensor(25123.3223, grad_fn=<AddBackward0>)\n",
      "tensor(24806.7383, grad_fn=<AddBackward0>)\n",
      "tensor(24645.4395, grad_fn=<AddBackward0>)\n",
      "tensor(25435.9414, grad_fn=<AddBackward0>)\n",
      "tensor(24941.3203, grad_fn=<AddBackward0>)\n",
      "tensor(24527.5781, grad_fn=<AddBackward0>)\n",
      "tensor(24627.8105, grad_fn=<AddBackward0>)\n",
      "tensor(24718.6270, grad_fn=<AddBackward0>)\n",
      "tensor(24548.7656, grad_fn=<AddBackward0>)\n",
      "tensor(25082.8691, grad_fn=<AddBackward0>)\n",
      "tensor(24622.2695, grad_fn=<AddBackward0>)\n",
      "tensor(24008.1719, grad_fn=<AddBackward0>)\n",
      "tensor(24372.0430, grad_fn=<AddBackward0>)\n",
      "tensor(24617.7520, grad_fn=<AddBackward0>)\n",
      "tensor(24406.0234, grad_fn=<AddBackward0>)\n",
      "tensor(23806.2988, grad_fn=<AddBackward0>)\n",
      "tensor(24167.6172, grad_fn=<AddBackward0>)\n",
      "tensor(23876.4434, grad_fn=<AddBackward0>)\n",
      "tensor(24414.8008, grad_fn=<AddBackward0>)\n",
      "tensor(23778.5605, grad_fn=<AddBackward0>)\n",
      "tensor(24265.2715, grad_fn=<AddBackward0>)\n",
      "tensor(24544.3457, grad_fn=<AddBackward0>)\n",
      "tensor(24199.7168, grad_fn=<AddBackward0>)\n",
      "tensor(24481.2246, grad_fn=<AddBackward0>)\n",
      "tensor(23895.9727, grad_fn=<AddBackward0>)\n",
      "tensor(23512.4570, grad_fn=<AddBackward0>)\n",
      "tensor(24058.5879, grad_fn=<AddBackward0>)\n",
      "tensor(23242.7930, grad_fn=<AddBackward0>)\n",
      "tensor(23390.4219, grad_fn=<AddBackward0>)\n",
      "tensor(23351.2441, grad_fn=<AddBackward0>)\n",
      "tensor(23186.8945, grad_fn=<AddBackward0>)\n",
      "tensor(23023.9492, grad_fn=<AddBackward0>)\n",
      "tensor(23282.5000, grad_fn=<AddBackward0>)\n",
      "tensor(23418.4512, grad_fn=<AddBackward0>)\n",
      "tensor(23610.9375, grad_fn=<AddBackward0>)\n",
      "tensor(23332.9863, grad_fn=<AddBackward0>)\n",
      "tensor(23245.2266, grad_fn=<AddBackward0>)\n",
      "tensor(23379.4551, grad_fn=<AddBackward0>)\n",
      "tensor(23330.7520, grad_fn=<AddBackward0>)\n",
      "tensor(23341.0059, grad_fn=<AddBackward0>)\n",
      "tensor(23038.1445, grad_fn=<AddBackward0>)\n",
      "tensor(23123.2051, grad_fn=<AddBackward0>)\n",
      "tensor(23288.7344, grad_fn=<AddBackward0>)\n",
      "tensor(23046.1641, grad_fn=<AddBackward0>)\n",
      "tensor(23180.5625, grad_fn=<AddBackward0>)\n",
      "tensor(23183.4785, grad_fn=<AddBackward0>)\n",
      "tensor(22697.6094, grad_fn=<AddBackward0>)\n",
      "tensor(23226.7617, grad_fn=<AddBackward0>)\n",
      "tensor(22944.1641, grad_fn=<AddBackward0>)\n",
      "tensor(22712.8711, grad_fn=<AddBackward0>)\n",
      "tensor(22265.1562, grad_fn=<AddBackward0>)\n",
      "tensor(22686.2793, grad_fn=<AddBackward0>)\n",
      "tensor(22304.1113, grad_fn=<AddBackward0>)\n",
      "tensor(22734.2832, grad_fn=<AddBackward0>)\n",
      "tensor(22458.7402, grad_fn=<AddBackward0>)\n",
      "tensor(23204.1113, grad_fn=<AddBackward0>)\n",
      "tensor(22020.9414, grad_fn=<AddBackward0>)\n",
      "tensor(22895.9473, grad_fn=<AddBackward0>)\n",
      "tensor(22617.5293, grad_fn=<AddBackward0>)\n",
      "tensor(22411.1367, grad_fn=<AddBackward0>)\n",
      "tensor(22390.0977, grad_fn=<AddBackward0>)\n",
      "tensor(22253.6270, grad_fn=<AddBackward0>)\n",
      "tensor(22266.0898, grad_fn=<AddBackward0>)\n",
      "tensor(22374.0020, grad_fn=<AddBackward0>)\n",
      "tensor(22470.4219, grad_fn=<AddBackward0>)\n",
      "tensor(22533.2324, grad_fn=<AddBackward0>)\n",
      "tensor(23162.2988, grad_fn=<AddBackward0>)\n",
      "tensor(22527.4180, grad_fn=<AddBackward0>)\n",
      "tensor(22262.9844, grad_fn=<AddBackward0>)\n",
      "tensor(22011.7441, grad_fn=<AddBackward0>)\n",
      "tensor(22150.3672, grad_fn=<AddBackward0>)\n",
      "tensor(22039.9863, grad_fn=<AddBackward0>)\n",
      "tensor(22224.7969, grad_fn=<AddBackward0>)\n",
      "tensor(22170.0664, grad_fn=<AddBackward0>)\n",
      "tensor(22026.0195, grad_fn=<AddBackward0>)\n",
      "tensor(22033.9883, grad_fn=<AddBackward0>)\n",
      "tensor(22166.4082, grad_fn=<AddBackward0>)\n",
      "tensor(22244.0430, grad_fn=<AddBackward0>)\n",
      "tensor(21412.7344, grad_fn=<AddBackward0>)\n",
      "tensor(21926.1172, grad_fn=<AddBackward0>)\n",
      "tensor(21521.0879, grad_fn=<AddBackward0>)\n",
      "tensor(21812.7031, grad_fn=<AddBackward0>)\n",
      "tensor(21331.6816, grad_fn=<AddBackward0>)\n",
      "tensor(21636.3633, grad_fn=<AddBackward0>)\n",
      "tensor(21557.3145, grad_fn=<AddBackward0>)\n",
      "tensor(21353.4023, grad_fn=<AddBackward0>)\n",
      "tensor(21825.8359, grad_fn=<AddBackward0>)\n",
      "tensor(21135.9727, grad_fn=<AddBackward0>)\n",
      "tensor(21227.9570, grad_fn=<AddBackward0>)\n",
      "tensor(21813.8398, grad_fn=<AddBackward0>)\n",
      "tensor(22111.2227, grad_fn=<AddBackward0>)\n",
      "tensor(21791.2969, grad_fn=<AddBackward0>)\n",
      "tensor(21291.9844, grad_fn=<AddBackward0>)\n",
      "tensor(21324.9375, grad_fn=<AddBackward0>)\n",
      "tensor(21305.1016, grad_fn=<AddBackward0>)\n",
      "tensor(21011.6602, grad_fn=<AddBackward0>)\n",
      "tensor(21243.0410, grad_fn=<AddBackward0>)\n",
      "tensor(21202.0625, grad_fn=<AddBackward0>)\n",
      "tensor(21400.6816, grad_fn=<AddBackward0>)\n",
      "tensor(21139.1895, grad_fn=<AddBackward0>)\n",
      "tensor(21191.8223, grad_fn=<AddBackward0>)\n",
      "tensor(21075.6680, grad_fn=<AddBackward0>)\n",
      "tensor(20282.6035, grad_fn=<AddBackward0>)\n",
      "tensor(21200.1953, grad_fn=<AddBackward0>)\n",
      "tensor(21907.8652, grad_fn=<AddBackward0>)\n",
      "tensor(20582.2578, grad_fn=<AddBackward0>)\n",
      "tensor(20826.4863, grad_fn=<AddBackward0>)\n",
      "tensor(20871.3398, grad_fn=<AddBackward0>)\n",
      "tensor(20874.2070, grad_fn=<AddBackward0>)\n",
      "tensor(20776.4609, grad_fn=<AddBackward0>)\n",
      "tensor(20635.6797, grad_fn=<AddBackward0>)\n",
      "tensor(21016.9375, grad_fn=<AddBackward0>)\n",
      "tensor(20695.3750, grad_fn=<AddBackward0>)\n",
      "tensor(20805.2910, grad_fn=<AddBackward0>)\n",
      "tensor(20386.3711, grad_fn=<AddBackward0>)\n",
      "tensor(20749.2910, grad_fn=<AddBackward0>)\n",
      "tensor(20384.8105, grad_fn=<AddBackward0>)\n",
      "tensor(20586.6348, grad_fn=<AddBackward0>)\n",
      "tensor(20816.5293, grad_fn=<AddBackward0>)\n",
      "tensor(20391.0059, grad_fn=<AddBackward0>)\n",
      "tensor(20380.5840, grad_fn=<AddBackward0>)\n",
      "tensor(20986.6523, grad_fn=<AddBackward0>)\n",
      "tensor(20501.5059, grad_fn=<AddBackward0>)\n",
      "tensor(20645.4102, grad_fn=<AddBackward0>)\n",
      "tensor(19965.5000, grad_fn=<AddBackward0>)\n",
      "tensor(20039.0977, grad_fn=<AddBackward0>)\n",
      "tensor(20085.1387, grad_fn=<AddBackward0>)\n",
      "tensor(20223.8789, grad_fn=<AddBackward0>)\n",
      "tensor(20131.1445, grad_fn=<AddBackward0>)\n",
      "tensor(20452.7930, grad_fn=<AddBackward0>)\n",
      "tensor(20813.9531, grad_fn=<AddBackward0>)\n",
      "tensor(20096.9082, grad_fn=<AddBackward0>)\n",
      "tensor(20155.8379, grad_fn=<AddBackward0>)\n",
      "tensor(20276.5742, grad_fn=<AddBackward0>)\n",
      "tensor(20221.8340, grad_fn=<AddBackward0>)\n",
      "tensor(19918.3711, grad_fn=<AddBackward0>)\n",
      "tensor(20214.1797, grad_fn=<AddBackward0>)\n",
      "tensor(20152.6133, grad_fn=<AddBackward0>)\n",
      "tensor(19617.0859, grad_fn=<AddBackward0>)\n",
      "tensor(20536.0762, grad_fn=<AddBackward0>)\n",
      "tensor(19744.8242, grad_fn=<AddBackward0>)\n",
      "tensor(19761.8984, grad_fn=<AddBackward0>)\n",
      "tensor(19874.3281, grad_fn=<AddBackward0>)\n",
      "tensor(19883.3359, grad_fn=<AddBackward0>)\n",
      "tensor(19530.0215, grad_fn=<AddBackward0>)\n",
      "tensor(19997.3340, grad_fn=<AddBackward0>)\n",
      "tensor(19629.5684, grad_fn=<AddBackward0>)\n",
      "tensor(19737.1328, grad_fn=<AddBackward0>)\n",
      "tensor(20181.0723, grad_fn=<AddBackward0>)\n",
      "tensor(19879.7656, grad_fn=<AddBackward0>)\n",
      "tensor(19797.1641, grad_fn=<AddBackward0>)\n",
      "tensor(19660.6523, grad_fn=<AddBackward0>)\n",
      "tensor(19603.8320, grad_fn=<AddBackward0>)\n",
      "tensor(19385.3965, grad_fn=<AddBackward0>)\n",
      "tensor(19522.2148, grad_fn=<AddBackward0>)\n",
      "tensor(20056.2773, grad_fn=<AddBackward0>)\n",
      "tensor(19764.5879, grad_fn=<AddBackward0>)\n",
      "tensor(19404.0859, grad_fn=<AddBackward0>)\n",
      "tensor(19566.6758, grad_fn=<AddBackward0>)\n",
      "tensor(19133.7363, grad_fn=<AddBackward0>)\n",
      "tensor(19678.1973, grad_fn=<AddBackward0>)\n",
      "tensor(19325.3672, grad_fn=<AddBackward0>)\n",
      "tensor(19061.5488, grad_fn=<AddBackward0>)\n",
      "tensor(18939.8770, grad_fn=<AddBackward0>)\n",
      "tensor(19104.4414, grad_fn=<AddBackward0>)\n",
      "tensor(18825.1426, grad_fn=<AddBackward0>)\n",
      "tensor(19370.2637, grad_fn=<AddBackward0>)\n",
      "tensor(18966.3262, grad_fn=<AddBackward0>)\n",
      "tensor(19379.9648, grad_fn=<AddBackward0>)\n",
      "tensor(19541.5293, grad_fn=<AddBackward0>)\n",
      "tensor(19308.1172, grad_fn=<AddBackward0>)\n",
      "tensor(19103.7402, grad_fn=<AddBackward0>)\n",
      "tensor(19710.2285, grad_fn=<AddBackward0>)\n",
      "tensor(19506.5547, grad_fn=<AddBackward0>)\n",
      "tensor(19071.5977, grad_fn=<AddBackward0>)\n",
      "tensor(19056.4844, grad_fn=<AddBackward0>)\n",
      "tensor(18875.1035, grad_fn=<AddBackward0>)\n",
      "tensor(18874.0195, grad_fn=<AddBackward0>)\n",
      "tensor(18975.6172, grad_fn=<AddBackward0>)\n",
      "tensor(19440.4160, grad_fn=<AddBackward0>)\n",
      "tensor(19220.1250, grad_fn=<AddBackward0>)\n",
      "tensor(19025.1895, grad_fn=<AddBackward0>)\n",
      "tensor(19039.0859, grad_fn=<AddBackward0>)\n",
      "tensor(18673.3887, grad_fn=<AddBackward0>)\n",
      "tensor(18803.5410, grad_fn=<AddBackward0>)\n",
      "tensor(18578.8340, grad_fn=<AddBackward0>)\n",
      "tensor(19064.2207, grad_fn=<AddBackward0>)\n",
      "tensor(18519.7266, grad_fn=<AddBackward0>)\n",
      "tensor(18746.4844, grad_fn=<AddBackward0>)\n",
      "tensor(18749., grad_fn=<AddBackward0>)\n",
      "tensor(18841.5117, grad_fn=<AddBackward0>)\n",
      "tensor(18434.3691, grad_fn=<AddBackward0>)\n",
      "tensor(18580.2422, grad_fn=<AddBackward0>)\n",
      "tensor(18778.1738, grad_fn=<AddBackward0>)\n",
      "tensor(18956.1602, grad_fn=<AddBackward0>)\n",
      "tensor(19002.1758, grad_fn=<AddBackward0>)\n",
      "tensor(19234.5605, grad_fn=<AddBackward0>)\n",
      "tensor(19073.7539, grad_fn=<AddBackward0>)\n",
      "tensor(18935.3711, grad_fn=<AddBackward0>)\n",
      "tensor(18808.5703, grad_fn=<AddBackward0>)\n",
      "tensor(18071.9004, grad_fn=<AddBackward0>)\n",
      "tensor(18506.5742, grad_fn=<AddBackward0>)\n",
      "tensor(18456.8691, grad_fn=<AddBackward0>)\n",
      "tensor(18110.5527, grad_fn=<AddBackward0>)\n",
      "tensor(18617.1250, grad_fn=<AddBackward0>)\n",
      "tensor(18160.9492, grad_fn=<AddBackward0>)\n",
      "tensor(18709.0156, grad_fn=<AddBackward0>)\n",
      "tensor(18345.7285, grad_fn=<AddBackward0>)\n",
      "tensor(18663.7480, grad_fn=<AddBackward0>)\n",
      "tensor(18618.2793, grad_fn=<AddBackward0>)\n",
      "tensor(18457.8457, grad_fn=<AddBackward0>)\n",
      "tensor(18261.4805, grad_fn=<AddBackward0>)\n",
      "tensor(17979.4707, grad_fn=<AddBackward0>)\n",
      "tensor(17921.1387, grad_fn=<AddBackward0>)\n",
      "tensor(18291.5000, grad_fn=<AddBackward0>)\n",
      "tensor(18297.8418, grad_fn=<AddBackward0>)\n",
      "tensor(18557.8516, grad_fn=<AddBackward0>)\n",
      "tensor(18238.1777, grad_fn=<AddBackward0>)\n",
      "tensor(18573.8008, grad_fn=<AddBackward0>)\n",
      "tensor(18343.6953, grad_fn=<AddBackward0>)\n",
      "tensor(17392.9922, grad_fn=<AddBackward0>)\n",
      "tensor(18540.9590, grad_fn=<AddBackward0>)\n",
      "tensor(18277.3652, grad_fn=<AddBackward0>)\n",
      "tensor(18104.8789, grad_fn=<AddBackward0>)\n",
      "tensor(17996.7539, grad_fn=<AddBackward0>)\n",
      "tensor(18316.5137, grad_fn=<AddBackward0>)\n",
      "tensor(17778.1758, grad_fn=<AddBackward0>)\n",
      "tensor(17758.8145, grad_fn=<AddBackward0>)\n",
      "tensor(17601.0664, grad_fn=<AddBackward0>)\n",
      "tensor(17841.3203, grad_fn=<AddBackward0>)\n",
      "tensor(17578.6172, grad_fn=<AddBackward0>)\n",
      "tensor(17943.9043, grad_fn=<AddBackward0>)\n",
      "tensor(18029.1797, grad_fn=<AddBackward0>)\n",
      "tensor(18221.3633, grad_fn=<AddBackward0>)\n",
      "tensor(17908.7148, grad_fn=<AddBackward0>)\n",
      "tensor(18057.2305, grad_fn=<AddBackward0>)\n",
      "tensor(18253.7812, grad_fn=<AddBackward0>)\n",
      "tensor(17911.2344, grad_fn=<AddBackward0>)\n",
      "tensor(17734.5918, grad_fn=<AddBackward0>)\n",
      "tensor(17950.7012, grad_fn=<AddBackward0>)\n",
      "tensor(18066.5684, grad_fn=<AddBackward0>)\n",
      "tensor(17980.5312, grad_fn=<AddBackward0>)\n",
      "tensor(17605.4453, grad_fn=<AddBackward0>)\n",
      "tensor(17807.5918, grad_fn=<AddBackward0>)\n",
      "tensor(17765.5469, grad_fn=<AddBackward0>)\n",
      "tensor(17727.3184, grad_fn=<AddBackward0>)\n",
      "tensor(17814.9414, grad_fn=<AddBackward0>)\n",
      "tensor(17491.8789, grad_fn=<AddBackward0>)\n",
      "tensor(17525.6621, grad_fn=<AddBackward0>)\n",
      "tensor(17654.6973, grad_fn=<AddBackward0>)\n",
      "tensor(17820.1562, grad_fn=<AddBackward0>)\n",
      "tensor(17567.4785, grad_fn=<AddBackward0>)\n",
      "tensor(17819.7344, grad_fn=<AddBackward0>)\n",
      "tensor(17532.2441, grad_fn=<AddBackward0>)\n",
      "tensor(17494.9453, grad_fn=<AddBackward0>)\n",
      "tensor(17237.7012, grad_fn=<AddBackward0>)\n",
      "tensor(17626.0547, grad_fn=<AddBackward0>)\n",
      "tensor(17459.8125, grad_fn=<AddBackward0>)\n",
      "tensor(17487.7578, grad_fn=<AddBackward0>)\n",
      "tensor(17997.9824, grad_fn=<AddBackward0>)\n",
      "tensor(17821.7090, grad_fn=<AddBackward0>)\n",
      "tensor(17054.7832, grad_fn=<AddBackward0>)\n",
      "tensor(17551.8516, grad_fn=<AddBackward0>)\n",
      "tensor(17779.3066, grad_fn=<AddBackward0>)\n",
      "tensor(17631.0078, grad_fn=<AddBackward0>)\n",
      "tensor(17929.9883, grad_fn=<AddBackward0>)\n",
      "tensor(17303.7715, grad_fn=<AddBackward0>)\n",
      "tensor(17131.3945, grad_fn=<AddBackward0>)\n",
      "tensor(17200.4824, grad_fn=<AddBackward0>)\n",
      "tensor(17171.9355, grad_fn=<AddBackward0>)\n",
      "tensor(17154.7695, grad_fn=<AddBackward0>)\n",
      "tensor(17237.6367, grad_fn=<AddBackward0>)\n",
      "tensor(17399.9062, grad_fn=<AddBackward0>)\n",
      "tensor(17137.2754, grad_fn=<AddBackward0>)\n",
      "tensor(17130.5234, grad_fn=<AddBackward0>)\n",
      "tensor(17462.9961, grad_fn=<AddBackward0>)\n",
      "tensor(17227.2656, grad_fn=<AddBackward0>)\n",
      "tensor(17316.2559, grad_fn=<AddBackward0>)\n",
      "tensor(17370.6250, grad_fn=<AddBackward0>)\n",
      "tensor(17303.9609, grad_fn=<AddBackward0>)\n",
      "tensor(16633.4395, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    encoder, decoder = torch.load('./model_CVAE/conv_variational_autoencoder.pkl')\n",
    "    print(\"\\n----------model restored----------\\n\")\n",
    "except:\n",
    "    print(\"\\n----------model not restored----------\\n\")\n",
    "    pass\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    for j, [image, label] in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mu, log_var, reparam = encoder(image)\n",
    "        output = decoder(reparam)\n",
    "        \n",
    "        loss = loss_function(output, image, mu, log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            torch.save([encoder, decoder], './model_CVAE/conv_variational_autoencoder.pkl')\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = torch.squeeze(output.cpu().data)\n",
    "print(out_img.size())\n",
    "\n",
    "plt.imshow(out_img[0].numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
