{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "mount_file_id": "1jTrISs7ERZt_Y6MOw53zdx8EQPge009s",
      "authorship_tag": "ABX9TyNMqTt5SDPOx5+F/pwHP0Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pko89403/DeepLearningSelfStudy/blob/master/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_a0FI9qFyvE",
        "colab_type": "text"
      },
      "source": [
        "## 진행되는 내용\n",
        "1. Data Definition ( Torch )\n",
        "2. Hypothesis ( Y = Wx + B )\n",
        "3. Compute loss\n",
        "4. Gradient Descent\n",
        "\n",
        "### 한번만\n",
        "1. 데이터 정의\n",
        "2. Hypothesis 초기화\n",
        "3. Optimizer 정의\n",
        "\n",
        "### 반복 !\n",
        "1. Hypothesis 예측\n",
        "2. Cost 계산\n",
        "3. Optimizer 로 학습\n",
        "\n",
        "Cost에 대한 Function이 나오는데 - prdict_val, true_val   \n",
        "Cost를 최소화하는 방향으로 weight와 bias를 개선 시킨다. \n",
        "\n",
        "- 시작할 때 optimizer 정의\n",
        "- optimizer.zero_grad() 로 gradient를 0 으로 초기화\n",
        "- cost.backward() 로 gradient 계산\n",
        "- optimizer.step() 으로 gradient descent "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw3wV_hcFWl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWKNOFe7F6tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]]) # 데이터 정의\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7_dBjSIN2Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = torch.zeros(1, requires_grad=True) # 학습할 것이라고 명시\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "hypothesis = x_train * W + b # Hypothesis를 예측"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8PPOSP3OQL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2) # Cost 계산"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVAQbPVIOgGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD([W,b], lr=0.1) # Optimizer 정의\n",
        "\n",
        "optimizer.zero_grad() # 계산하려는 Gradient를 초기화\n",
        "cost.backward() # gradient 계산\n",
        "optimizer.step() # step()으로 개선"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyfOpUxBOz_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "79402927-68cc-4bd8-b5b3-6aa4d8df8c6a"
      },
      "source": [
        "for epoch in range(10):\n",
        "  hypothesis = x_train * W + b # Hypothesis를 예측\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2) # Cost 계산\n",
        "\n",
        "  print('Epoch {:4d}/{} W: {:.3f} Cost: {:.6f}'.format(epoch, 10, W.item(), cost.item()))\n",
        "\n",
        "  optimizer.zero_grad() # 계산하려는 Gradient를 초기화\n",
        "  cost.backward() # gradient 계산\n",
        "  optimizer.step() # step()으로 개선"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/10 W: 0.933 Cost: 0.074074\n",
            "Epoch    1/10 W: 0.836 Cost: 0.018344\n",
            "Epoch    2/10 W: 0.850 Cost: 0.016849\n",
            "Epoch    3/10 W: 0.853 Cost: 0.016041\n",
            "Epoch    4/10 W: 0.856 Cost: 0.015279\n",
            "Epoch    5/10 W: 0.860 Cost: 0.014553\n",
            "Epoch    6/10 W: 0.863 Cost: 0.013862\n",
            "Epoch    7/10 W: 0.867 Cost: 0.013204\n",
            "Epoch    8/10 W: 0.870 Cost: 0.012576\n",
            "Epoch    9/10 W: 0.873 Cost: 0.011979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbWGK8QNS23D",
        "colab_type": "text"
      },
      "source": [
        "# Multivariate Liear Regression\n",
        "### nn.Module\n",
        "- nn.Module을 상속해서 모델 생성\n",
        "- nn.Linear(3, 1) : 입력 차원 3, 출력 차원 1\n",
        "- Hypothesis 계산은 forward() 에서!\n",
        "- Gradient 계산은 Pytorch가 알아서 해준다. backward()\n",
        "\n",
        "### torch.nn.functional의 loss function 사용\n",
        "- 쉽게 다른 loss function으로 변경 가능\n",
        "\n",
        "### PyTorch Dataset\n",
        "- torch.utils.data.Dataset 상속\n",
        "- __len__()\n",
        "  - 이 데이터셋의 총 데이터 수\n",
        "- __getitem__()\n",
        "  - 어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터 반환\n",
        "\n",
        "### PyTorch DataLoader\n",
        "- torch.utils.data.DataLoader 사용\n",
        "- batch_size\n",
        "- shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwCdqzhQSS63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegressionModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZStBvt_S4O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "dataset = CustomDataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frwkvXIBYBBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfNCx79xX4nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "180924e8-4d91-4d58-a635-856f4b8a1586"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "for epoch in range(10):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "\n",
        "    prediction = model(x_train)\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad() # 계산하려는 Gradient를 초기화\n",
        "    cost.backward() # gradient 계산\n",
        "    optimizer.step() # step()으로 개선\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch : {}/{} Cost: {:.6f}'.format(epoch, 10, batch_idx+1, len(dataloader), cost.item()))\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/10 Batch : 1/3 Cost: 41711.484375\n",
            "Epoch    0/10 Batch : 2/3 Cost: 48669.125000\n",
            "Epoch    0/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    1/10 Batch : 1/3 Cost: 51862.750000\n",
            "Epoch    1/10 Batch : 2/3 Cost: 48669.125000\n",
            "Epoch    1/10 Batch : 3/3 Cost: 30735.060547\n",
            "Epoch    2/10 Batch : 1/3 Cost: 44837.386719\n",
            "Epoch    2/10 Batch : 2/3 Cost: 45543.222656\n",
            "Epoch    2/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    3/10 Batch : 1/3 Cost: 44837.386719\n",
            "Epoch    3/10 Batch : 2/3 Cost: 45543.222656\n",
            "Epoch    3/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    4/10 Batch : 1/3 Cost: 41711.484375\n",
            "Epoch    4/10 Batch : 2/3 Cost: 48669.125000\n",
            "Epoch    4/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    5/10 Batch : 1/3 Cost: 33860.964844\n",
            "Epoch    5/10 Batch : 2/3 Cost: 56519.648438\n",
            "Epoch    5/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    6/10 Batch : 1/3 Cost: 48669.125000\n",
            "Epoch    6/10 Batch : 2/3 Cost: 41711.484375\n",
            "Epoch    6/10 Batch : 3/3 Cost: 51037.597656\n",
            "Epoch    7/10 Batch : 1/3 Cost: 33860.964844\n",
            "Epoch    7/10 Batch : 2/3 Cost: 51862.750000\n",
            "Epoch    7/10 Batch : 3/3 Cost: 60351.386719\n",
            "Epoch    8/10 Batch : 1/3 Cost: 55694.492188\n",
            "Epoch    8/10 Batch : 2/3 Cost: 44837.386719\n",
            "Epoch    8/10 Batch : 3/3 Cost: 30735.060547\n",
            "Epoch    9/10 Batch : 1/3 Cost: 40886.328125\n",
            "Epoch    9/10 Batch : 2/3 Cost: 56519.648438\n",
            "Epoch    9/10 Batch : 3/3 Cost: 36986.867188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpYLtexlYp0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}