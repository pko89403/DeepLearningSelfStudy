{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequence_models_tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk3zJ+MSZlLnG12AvC5ZNp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pko89403/DeepLearningSelfStudy/blob/master/sequence_models_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PmeiPUGTcHZ",
        "colab_type": "text"
      },
      "source": [
        "# 시퀀스 모델과 LSTM 네트워크\n",
        "이전에 많은 모델을 보았지만, 네트워크에서 전적으로 유지되는 스테이트는 없다. 시퀀스 모델은  NLP에서 메인이다. 여기서 말하는 시퀀스 모델은 인풋 사이의 시간에 어느정도 의존하는 모델이다. 전통적인 시퀀스 모델은 히든 마코프 모델. \n",
        "RNN 모델은 어떤 상태를 유지하는 모델이다. 예를 들어, 아웃풋이 다음 입력의 한 파트로 사용될 수도 있다. 따라서 정보가 시퀀스에 대해 네트워크를 따라 전파될 수 있다. LSTM의 경우, 시퀀스의 각 요소들이 히든 스테이트로 할당 될 수 있다. 히든 스테이트를 예측하는데 사용할 수 있다.\n",
        "\n",
        "## 파이토치 에서의 LSTM\n",
        "파이토치에서 LSTM은 모든 입력들을 3D 텐서로 예상한다. 이러한 텐서들이 가지는 축들의 의미는 매우 중요하다. \n",
        "- 첫번째 축은 시퀀스, 데이터가 가지는 타임스탬프의 길이 자체다.\n",
        "- 두번째 인덱스는 mini-batch size, 데이터 배치 사이즈\n",
        "- 그리고 세번째 인덱스는 한 타임스탬프가 가지는 입력 데이터의 차원\n",
        "\n",
        "> The cow jumped 는 (1,1,3)이 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQCIAtsWUrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "becdebe3-3678-494b-fb67-79dfe936b334"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f59a11057f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsJLkEOnW4QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = nn.LSTM(3, 3) # Input dim is 3, Output dim is 3\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)] # make a sequence of length 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kz7sDlMXhMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "38533633-e884-4fd0-91c5-4e8a356bf6b0"
      },
      "source": [
        "# 히든 스테이트를 초기화\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3))\n",
        "for i in inputs:\n",
        "  # 한 번에 한 요소 씩 시퀀스를 단계 별로 진행한다\n",
        "  # 각 단계 후에, 히든은 히든 스테이트를 포함한다.\n",
        "  out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
        "  print('out\\t' , out, '\\thidden\\t', hidden)\n",
        "\n",
        "  # 대안으로, 전 시퀀스를 한번에 다 할 수 있다.\n",
        "  # LSTM에서 반환된 첫번째 값은 모든 히든 스테이트 결과들이다\n",
        "  # 시퀀스다. 두번째는 가장 최근의 히든 스테이트다\n",
        "  # ( out의 마지막 조각과 hidden을 비교하면 같다. )\n",
        "  # \"out\"은 시퀀스 내의 모든 히든 스테이트에 접근하게 한다.\n",
        "  # \"hidden\"은 시퀀스와 백-프로파게이션을 계속하는 것을 허용한다\n",
        "  # 마지막 time에 argument로 lstm에 전달하면\n",
        "  # 추가 2차원을 더한다\n",
        "\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3)) \n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print('Out - ', out)\n",
        "print('Hidden - ', hidden)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out\t tensor([[[0.2179, 0.0546, 0.2426]]], grad_fn=<StackBackward>) \thidden\t (tensor([[[0.2179, 0.0546, 0.2426]]], grad_fn=<StackBackward>), tensor([[[0.3195, 0.1672, 0.9442]]], grad_fn=<StackBackward>))\n",
            "out\t tensor([[[0.0585, 0.0731, 0.2434]]], grad_fn=<StackBackward>) \thidden\t (tensor([[[0.0585, 0.0731, 0.2434]]], grad_fn=<StackBackward>), tensor([[[0.0950, 0.1684, 0.6035]]], grad_fn=<StackBackward>))\n",
            "out\t tensor([[[ 0.1322, -0.0984,  0.0183]]], grad_fn=<StackBackward>) \thidden\t (tensor([[[ 0.1322, -0.0984,  0.0183]]], grad_fn=<StackBackward>), tensor([[[ 0.2221, -0.4208,  0.0376]]], grad_fn=<StackBackward>))\n",
            "out\t tensor([[[ 0.1115, -0.1652,  0.0573]]], grad_fn=<StackBackward>) \thidden\t (tensor([[[ 0.1115, -0.1652,  0.0573]]], grad_fn=<StackBackward>), tensor([[[ 0.1788, -0.4906,  0.1991]]], grad_fn=<StackBackward>))\n",
            "out\t tensor([[[0.0456, 0.1216, 0.0614]]], grad_fn=<StackBackward>) \thidden\t (tensor([[[0.0456, 0.1216, 0.0614]]], grad_fn=<StackBackward>), tensor([[[0.0836, 0.2870, 0.1104]]], grad_fn=<StackBackward>))\n",
            "Out -  tensor([[[ 0.0541, -0.0978, -0.2422]],\n",
            "\n",
            "        [[ 0.0341, -0.0101, -0.2449]],\n",
            "\n",
            "        [[ 0.1207, -0.0815, -0.2100]],\n",
            "\n",
            "        [[ 0.1208, -0.1381, -0.0162]],\n",
            "\n",
            "        [[ 0.0541,  0.1328, -0.0340]]], grad_fn=<StackBackward>)\n",
            "Hidden -  (tensor([[[ 0.0541,  0.1328, -0.0340]]], grad_fn=<StackBackward>), tensor([[[ 0.1003,  0.3260, -0.0614]]], grad_fn=<StackBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpCjyzj5eIaE",
        "colab_type": "text"
      },
      "source": [
        "## 예제 : Part-of-Speech 태깅을 위한 LSTM\n",
        "LSTM을 speech tag의 부분을 얻기 위해 사용한다.   \n",
        "문장을 입력해서 vocab의 word들로 이루어졌다. 예측은 word를 예측하고\n",
        "구조적으로 보았을 때 모델의 아웃풋은 태그들로 이루어진 시퀀스다.    \n",
        "예측을 하기위해 LSTM으로 문장을 전달하고. 로그 소프트 맥스를 씌워서 argmax를 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI7FRH6jYQQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1076b54-a8a1-4b08-e9d3-3843a048d454"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = [to_ix[w] for w in seq]\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "training_data = [\n",
        "  (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "  (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "word_to_idx = {}\n",
        "for sent, tags in training_data:\n",
        "  for word in sent:\n",
        "    if word not in word_to_idx:\n",
        "      word_to_idx[word] = len(word_to_idx)\n",
        "\n",
        "print(word_to_idx)\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEM_DIM = 6"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWolDs6ohuaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "    super(LSTMTagger, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # LSTM은 워드 임베딩을 입력 받고 히든 스테이트를 출력한다.\n",
        "    # hidden_dim 으로 정의한 차원으로\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "    # 리니어 레이어는 히든 스테이트 공간에서 태그 스페이스로 매핑한다.\n",
        "    self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embeds = self.word_embeddings(sentence)\n",
        "    print(embeds)\n",
        "    print(embeds.shape)\n",
        "    lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "    print(lstm_out)\n",
        "    print(_)\n",
        "    tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "    return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErGsG5MAlUw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b448799a-4ab6-40e7-e269-52ce8b945cbf"
      },
      "source": [
        "model = LSTMTagger(embedding_dim=EMBEDDING_DIM,\n",
        "                   hidden_dim=HIDDEM_DIM,\n",
        "                   vocab_size=len(word_to_idx),\n",
        "                   tagset_size=len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMTagger(\n",
            "  (word_embeddings): Embedding(9, 6)\n",
            "  (lstm): LSTM(6, 6)\n",
            "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGSkQWA_mJ-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b459bc80-a62c-4a27-91a9-53024d78e255"
      },
      "source": [
        "with torch.no_grad():\n",
        "  print(training_data[0][0])\n",
        "  inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
        "  print(inputs)\n",
        "  tag_scores = model(inputs)\n",
        "  print(tag_scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'dog', 'ate', 'the', 'apple']\n",
            "tensor([0, 1, 2, 3, 4])\n",
            "tensor([[-0.5454,  0.0985, -0.1218,  0.3274, -1.0497,  0.2502],\n",
            "        [ 1.7113,  0.9126, -0.0169,  1.4172, -0.4237, -0.0769],\n",
            "        [ 0.5362,  0.6485,  0.1329, -0.1203,  1.4280,  0.5847],\n",
            "        [-1.3204, -0.2781, -1.4720,  1.2683,  0.7452, -0.3816],\n",
            "        [-0.6646, -1.4525,  0.1274,  1.6439, -0.3111, -1.0572]])\n",
            "torch.Size([5, 6])\n",
            "tensor([[[-6.8528e-02, -4.2312e-05,  1.3350e-01,  1.4006e-01, -6.3120e-03,\n",
            "           1.0050e-01]],\n",
            "\n",
            "        [[-1.0207e-01,  6.3780e-02,  1.0711e-01, -1.4232e-01, -4.9737e-02,\n",
            "           1.7420e-01]],\n",
            "\n",
            "        [[-8.0842e-02,  5.6233e-03,  1.2488e-01, -2.1802e-01, -5.5637e-02,\n",
            "          -1.1259e-01]],\n",
            "\n",
            "        [[-1.9890e-01,  1.3407e-01,  2.6237e-01,  1.1725e-01,  7.7432e-02,\n",
            "           4.1564e-02]],\n",
            "\n",
            "        [[-3.0839e-01,  1.5909e-01,  2.2927e-01,  1.4703e-01,  5.4129e-02,\n",
            "           5.1054e-02]]])\n",
            "(tensor([[[-0.3084,  0.1591,  0.2293,  0.1470,  0.0541,  0.0511]]]), tensor([[[-0.6432,  0.5055,  0.6836,  0.3960,  0.1823,  0.3140]]]))\n",
            "tensor([[-0.8692, -1.2669, -1.2073],\n",
            "        [-0.9927, -1.2815, -1.0447],\n",
            "        [-0.9718, -1.1951, -1.1428],\n",
            "        [-0.9181, -1.2389, -1.1679],\n",
            "        [-0.9034, -1.2687, -1.1596]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGHV_z5Smisl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d574113b-3f0c-44c9-ae8d-9a901c7921cd"
      },
      "source": [
        "for epoch in range(300):\n",
        "  for sentence, tags in training_data:\n",
        "    model.zero_grad()\n",
        "\n",
        "    sentence_in = prepare_sequence(sentence, word_to_idx)\n",
        "    targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "    print(sentence)\n",
        "    print(tags)\n",
        "    tag_scores = model(sentence_in)\n",
        "\n",
        "    loss = loss_function(tag_scores, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    break\n",
        "  break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'dog', 'ate', 'the', 'apple']\n",
            "['DET', 'NN', 'V', 'DET', 'NN']\n",
            "tensor([[-0.9762,  0.2633, -0.6479, -0.3214, -0.4275, -0.2357],\n",
            "        [ 2.1305,  0.7399,  0.1118,  2.0102, -0.6656, -0.1144],\n",
            "        [ 0.6298,  1.1102,  0.1137,  0.2235,  1.9730,  0.9110],\n",
            "        [-1.6952, -0.2764, -1.7232,  0.9574,  0.8487, -0.5334],\n",
            "        [-0.1292, -1.6864,  0.5710,  2.2424, -0.2707, -1.0105]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "torch.Size([5, 6])\n",
            "tensor([[[-0.6522, -0.0516, -0.1285,  0.5599, -0.0093,  0.0445]],\n",
            "\n",
            "        [[-0.0136,  0.6433,  0.4422, -0.0764, -0.1803,  0.7546]],\n",
            "\n",
            "        [[-0.6472, -0.2401, -0.3885, -0.8307,  0.3115,  0.8788]],\n",
            "\n",
            "        [[-0.8867,  0.0977, -0.3808,  0.6480,  0.1277,  0.0385]],\n",
            "\n",
            "        [[-0.0270,  0.7632,  0.5838,  0.2779,  0.0957,  0.2289]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "(tensor([[[-0.0270,  0.7632,  0.5838,  0.2779,  0.0957,  0.2289]]],\n",
            "       grad_fn=<StackBackward>), tensor([[[-0.4805,  1.0634,  0.7367,  0.7821,  0.3151,  1.1021]]],\n",
            "       grad_fn=<StackBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CHBpf5uqIXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f145a632-2fe8-4728-d214-3d44b6c4de33"
      },
      "source": [
        "with torch.no_grad():\n",
        "  inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
        "  tag_scores = model(inputs)\n",
        "\n",
        "  # 문장은 \"the dog ate the apple\". \n",
        "  # word 인 i에 대해서 예측된 태그는 최대 점수인 태그다.\n",
        "  # 여기서 아래 시퀀스에서 예측된 시퀀스는 0 1 2 0 1\n",
        "  # 0이 row 1에서의 최댓값의 인덱스이기 때문에\n",
        "  # 1이 row 2에서의 최댓값의 인덱스이기 때문에\n",
        "  # DET NOUN VERB DET NOUN 인 정답 시퀀스\n",
        "  print(tag_scores)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9764,  0.2633, -0.6481, -0.3215, -0.4274, -0.2358],\n",
            "        [ 2.1306,  0.7398,  0.1118,  2.0104, -0.6656, -0.1144],\n",
            "        [ 0.6299,  1.1103,  0.1137,  0.2236,  1.9732,  0.9111],\n",
            "        [-1.6953, -0.2764, -1.7232,  0.9574,  0.8487, -0.5334],\n",
            "        [-0.1289, -1.6864,  0.5712,  2.2426, -0.2706, -1.0105]])\n",
            "torch.Size([5, 6])\n",
            "tensor([[[-0.6523, -0.0516, -0.1287,  0.5600, -0.0093,  0.0445]],\n",
            "\n",
            "        [[-0.0136,  0.6433,  0.4423, -0.0764, -0.1803,  0.7547]],\n",
            "\n",
            "        [[-0.6472, -0.2402, -0.3886, -0.8307,  0.3116,  0.8788]],\n",
            "\n",
            "        [[-0.8868,  0.0978, -0.3810,  0.6480,  0.1276,  0.0385]],\n",
            "\n",
            "        [[-0.0270,  0.7633,  0.5839,  0.2777,  0.0957,  0.2292]]])\n",
            "(tensor([[[-0.0270,  0.7633,  0.5839,  0.2777,  0.0957,  0.2292]]]), tensor([[[-0.4804,  1.0635,  0.7367,  0.7821,  0.3151,  1.1025]]]))\n",
            "tensor([[-0.0235, -4.1235, -4.9611],\n",
            "        [-5.3857, -0.0140, -4.6774],\n",
            "        [-4.3891, -5.6104, -0.0162],\n",
            "        [-0.0098, -5.2722, -5.3769],\n",
            "        [-4.3830, -0.0140, -6.5810]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzt_zIlnsQ3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}