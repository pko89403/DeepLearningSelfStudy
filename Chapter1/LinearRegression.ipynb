{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치\n",
    "페이스북의 인공지능 프레임워크, 사용하면 건강해진다.\n",
    "\n",
    "파이토치에서는 데이터의 기본 단위로 tensor를 사용한다. tensor는 다차원 배열(array) 라고 정의할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀분석\n",
    "주어진 데이터를 가장 잘 설명하는 직선 하나를 찾는 것.\n",
    "- 하나의 독립변수 : Simple Linear Regression\n",
    "- 여러개 독립변수 : Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor 함수는 인수로 data, dtype, device, requires_grad 등을 받는다.\n",
    "- data : 배열이 들어간다.\n",
    "- dtype : 데이터를 저장할 자료형이 들어간다.\n",
    "- device : tensor를 어느 기기에 올릴건지 명시한다.\n",
    "- requires_grad : 이 tensor에 대한 기울기를 저장할지 여부를 지정한다. ( Default : False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 2.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 1.1210e-44, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.Tensor(2, 3)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor( [[1,2,3], [4,5,6]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor(data=[2.0, 3.0], requires_grad=True)\n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 z의 식에서 x에 대한 기울기를 구하는 단순한 코드.\\\n",
    "x라는 텐서를 생성하며 기울기를 계산하도록 지정했고, 따라서 z라는 변수에 연산 그래프의 결괏값이 저장됩니다.\\\n",
    "z와 target 절댓값 차이를 계산하고 torch.sum()이란 함수를 통해 두 값의 차이를 숫자 하나로 바꾼다.\\\n",
    "loss.backward() 함수를 호출하면 연산 그래프를 쭉 따라가면서 잎노드(x)에 대한 기울기를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([ 8., 12.]) None None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(data=[2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3.0, 4.0])\n",
    "loss = torch.sum(torch.abs( z - target ))\n",
    "loss.backward()\n",
    "\n",
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x 라는 변수에 [num_data, 1] 모양의 텐서를 생성하는데 이 tensor의 값을 -10 부터 10 까지 균등하게 초기화\\\n",
    "y 에 노이즈를 추가하기 위해 y_noise 라는 변수 정규분포를 따르는 변수를 초기화한다\\\n",
    "Linear 클래스는 들어오는 feature의 수, 결과로 나오는 feature의 수, bias 사용 여부를 초기화 인수로 받아서 생성\\\n",
    "최적화 할 변수로 model.prameters()라는 함수를 사용하여 선형회귀 모델의 변수 w와 b를 전달헀고 lr을 전달했다\\\n",
    "각 반복시 지난번에 계산했던 기울기를 0으로 초기화하는 optimizer.zero_grad()를 실행한다\\\n",
    "기울기를 초기화해야 새로운 가중치와 편차에 대해 새로운 기울기를 구할 수 있기 떄문이다\\\n",
    "loss에 output과 y_noise의 차이를 저장하고 loss.backward() 함수를 호출하면 각 변수 w, b에 대한 기울기가 계산된다\\\n",
    "optmizer의 step 함수를 통해 인수로 들어갔던 model.parameters()에서 리턴되는 변수들의 기울기에 학습율 0.01을 곱하여 빼줌으로써 업데이트한다\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.4425)\n",
      "0.4011380672454834 0.9391444325447083\n",
      "tensor(6.1787)\n",
      "0.8753024339675903 0.9556044340133667\n",
      "tensor(4.1668)\n",
      "1.319082498550415 0.9800844788551331\n",
      "tensor(2.8963)\n",
      "1.6609995365142822 1.0201045274734497\n",
      "tensor(2.4223)\n",
      "1.8570470809936523 1.074844479560852\n",
      "tensor(2.3059)\n",
      "1.9358597993850708 1.13418447971344\n",
      "tensor(2.2605)\n",
      "1.9668447971343994 1.193204641342163\n",
      "tensor(2.2237)\n",
      "1.9844006299972534 1.2506046295166016\n",
      "tensor(2.1918)\n",
      "1.9906543493270874 1.3064446449279785\n",
      "tensor(2.1625)\n",
      "1.9930152893066406 1.3604249954223633\n",
      "tensor(2.1343)\n",
      "1.992275595664978 1.4134451150894165\n",
      "tensor(2.1072)\n",
      "1.9896851778030396 1.4653050899505615\n",
      "tensor(2.0823)\n",
      "1.988305926322937 1.5150450468063354\n",
      "tensor(2.0587)\n",
      "1.9865025281906128 1.5635448694229126\n",
      "tensor(2.0363)\n",
      "1.988284707069397 1.6106847524642944\n",
      "tensor(2.0152)\n",
      "1.990668535232544 1.6563447713851929\n",
      "tensor(1.9957)\n",
      "1.9915516376495361 1.7005046606063843\n",
      "tensor(1.9767)\n",
      "1.994051218032837 1.743884801864624\n",
      "tensor(1.9592)\n",
      "1.9960625171661377 1.785544753074646\n",
      "tensor(1.9426)\n",
      "1.9983572959899902 1.8262051343917847\n",
      "tensor(1.9268)\n",
      "2.0012357234954834 1.865625262260437\n",
      "tensor(1.9123)\n",
      "2.0016844272613525 1.90370512008667\n",
      "tensor(1.8984)\n",
      "2.000249147415161 1.9407252073287964\n",
      "tensor(1.8854)\n",
      "2.0000221729278564 1.9767253398895264\n",
      "tensor(1.8732)\n",
      "1.999893307685852 2.0116450786590576\n",
      "tensor(1.8617)\n",
      "1.9996274709701538 2.045405387878418\n",
      "tensor(1.8509)\n",
      "2.0005524158477783 2.0781850814819336\n",
      "tensor(1.8405)\n",
      "2.0004656314849854 2.110365867614746\n",
      "tensor(1.8305)\n",
      "2.002519369125366 2.1419057846069336\n",
      "tensor(1.8212)\n",
      "2.003279447555542 2.1724064350128174\n",
      "tensor(1.8123)\n",
      "2.003671884536743 2.2019665241241455\n",
      "tensor(1.8045)\n",
      "2.0035324096679688 2.229926347732544\n",
      "tensor(1.7968)\n",
      "2.00213623046875 2.257645845413208\n",
      "tensor(1.7894)\n",
      "2.001991033554077 2.2846462726593018\n",
      "tensor(1.7827)\n",
      "2.0042295455932617 2.310246229171753\n",
      "tensor(1.7768)\n",
      "2.0031626224517822 2.334506034851074\n",
      "tensor(1.7714)\n",
      "2.0038681030273438 2.35758638381958\n",
      "tensor(1.7668)\n",
      "2.0028674602508545 2.378946542739868\n",
      "tensor(1.7625)\n",
      "2.0021300315856934 2.3995258808135986\n",
      "tensor(1.7586)\n",
      "2.001936197280884 2.4192261695861816\n",
      "tensor(1.7549)\n",
      "2.000563859939575 2.438185691833496\n",
      "tensor(1.7515)\n",
      "2.0004947185516357 2.456646203994751\n",
      "tensor(1.7482)\n",
      "2.0008602142333984 2.4748270511627197\n",
      "tensor(1.7451)\n",
      "2.003028154373169 2.492166757583618\n",
      "tensor(1.7423)\n",
      "2.004302978515625 2.5089268684387207\n",
      "tensor(1.7396)\n",
      "2.005594253540039 2.52520751953125\n",
      "tensor(1.7370)\n",
      "2.0073628425598145 2.541287899017334\n",
      "tensor(1.7346)\n",
      "2.0089216232299805 2.556647300720215\n",
      "tensor(1.7324)\n",
      "2.0086286067962646 2.5714075565338135\n",
      "tensor(1.7303)\n",
      "2.006603240966797 2.585667848587036\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "num_data = 1000\n",
    "num_epoch = 500\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "y = 2*x + 3\n",
    "y_noise = 2 * (x + noise) + 3\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "label = y_noise\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        param_list = list(model.parameters())\n",
    "        print(param_list[0].item(), param_list[1].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_kernel",
   "language": "python",
   "name": "pytorch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
